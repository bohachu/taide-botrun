# 地雷經驗：OpenRouter API LLM 模型測試台灣高中國文學測

## 發生時機
- 使用 OpenRouter API 測試 LLM 回答台灣高中國文題目
- 測試模型對繁體中文、台灣文學史的理解能力
- 比較不同模型在特定領域的表現差異

## 問題描述

### 1. 免費模型 Token 計數問題
- **現象**: Gemma 3 12B IT (Free) 的 output_tokens 顯示為 0
- **原因**: OpenRouter 免費模型可能不回報完整的 token 使用資訊
- **解決**: 紀錄此現象，實際上模型有輸出，只是統計不完整

### 2. 文學史知識錯誤
- **現象**: 兩個模型都在 LK-002（建安七子）題目答錯
- **具體錯誤**:
  - Gemini 認為「《典論・論文》作者是曹操」（應為曹丕）
  - 兩模型都認為「選項 A 正確」（名單與三曹並稱）而忽略更精確的選項 C
- **原因**: 訓練資料中中文文學史內容不足或不夠深入
- **啟示**: 台灣高中國文需要專門的 fine-tuning 或 RAG 補充

### 3. 字形辨識能力差異
- **現象**: Gemini 2.0 Flash 在字形題表現較佳（2/2），Gemma 3 12B IT 較差（0/2）
- **原因**: Gemma 可能在繁體中文字形訓練資料不足
- **啟示**: 繁體中文 NLP 任務應優先考慮支援較好的模型

### 4. 回應速度差異顯著
- **Gemma 3 12B IT**: 平均 3.89 秒/題
- **Gemini 2.0 Flash**: 平均 0.76 秒/題（快 5 倍）
- **啟示**: 生產環境需考量延遲與成本的平衡

## 測試結果摘要
| 模型 | 正確率 | 字形題 | 文學史題 |
|------|--------|--------|----------|
| Gemma 3 12B IT | 40% (2/5) | 0/2 | 2/3 |
| Gemini 2.0 Flash | 60% (3/5) | 2/2 | 1/3 |

## 建議做法

### 題目驗算必要性
1. 自動生成的題目必須先用網路資料驗算
2. 假設原答案可能錯誤，主動查找證據
3. 記錄驗證來源，提高資料可信度

### API 測試腳本設計
1. 使用 .mjs 純 ESM 格式，避免依賴管理問題
2. 手動實作 .env 載入，不依賴 dotenv 套件
3. 實作重試機制（2-3 次），處理暫時性錯誤
4. 計算並記錄 response time、token usage
5. 輸出 JSON 與 Markdown 雙格式報告

### Prompt 設計
```
你是一位台灣高中國文老師，正在協助學生進行學測模擬考。
請仔細閱讀以下題目，選出正確答案。

【作答要求】
1. 請直接回答選項代號（A、B、C 或 D）
2. 簡要說明你的推理過程（2-3 句話）
3. 格式範例：
   答案：B
   理由：因為...所以選擇 B。
```

## 相關檔案
- 測試腳本: step-004-抽取5提問來訓練/scripts/test-openrouter.mjs
- 驗算結果: step-004-抽取5提問來訓練/data/verified-questions.jsonl
- 測試報告: step-004-抽取5提問來訓練/reports/baseline-report.md

## 記錄日期
2025-12-13
